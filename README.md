# Diploma_Work
Այս նախագիծը ներկայացնում է Q-ուսուցման (Q-Learning) ալգորիթմի իրականացումը OpenAI Gym գրադարանի FrozenLake-v1 միջավայրի վրա։
Գործակալը սովորում է հասնել նպատակին՝ խուսափելով փոսերից՝ աշխատելով սայթաքուն (ստոխաստիկ) միջավայրում։

Օգտագործվող գրադարաններ`

1.numpy

2.gym

3.matplotlib

Սկզբում ստեղծվում է ուսուցման միջավայրը՝ FrozenLake-v1։

Սահմանվում են Q աղյուսակի չափսերը՝ ըստ միջավայրի վիճակների և գործողությունների քանակի։

Գործակալը կիրառում է epsilon-greedy քաղաքականություն՝ միջավայրում քայլեր կատարելու համար։

Ամեն քայլի արդյունքում թարմացվում է Q-աղյուսակը հետևյալ կանոնով.

![image](https://github.com/user-attachments/assets/6d67b82c-6c1e-4ce0-88f4-1d1f69abec24)

Արտադրանքի առաջընթացը գրաֆիկով (Rewards per Episode):

![image](https://github.com/user-attachments/assets/7056c45b-09df-4f25-a74c-1a5e082e6b40)

Նկարում երևում է, թե ինչպես է գործակալը ժամանակի ընթացքում ավելի շատ պարգևատրումներ ստանում։

Դրանից հետո գործակալը փորձարկվում է սովորած քաղաքականությամբ.

![image](https://github.com/user-attachments/assets/614fa25f-76d2-44d2-b221-958623722d0b)

Նկարում ցուցադրված է FrozenLake միջավայրը իրական ժամանակում փորձարկման ընթացքում։


